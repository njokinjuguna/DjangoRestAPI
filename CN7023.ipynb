{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMV0tKNxiH0x8Pg3DEvMniM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njokinjuguna/DjangoRestAPI/blob/main/CN7023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CDgn00_zTFTE"
      },
      "outputs": [],
      "source": [
        "#importing modules\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten,BatchNormalization, Activation, Dropout\n",
        "# from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "from tensorflow.keras.backend import epsilon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#import matplotlib for image processing\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten\n",
        "import confusion_matrix,plot_confusion_matrix\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F25KtKpOU_XI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install plot_confusion_matrix"
      ],
      "metadata": {
        "id": "6ydabaCNlSC1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n"
      ],
      "metadata": {
        "id": "K6kDRJLGVKRo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reading the dataset\n",
        "(X_train, y_train), (X_test, y_test) =cifar10.load_data()"
      ],
      "metadata": {
        "id": "B8Du-v6RVMAh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confirm the number of images in each set\n",
        "X_train.shape\n",
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK7GOXynVRip",
        "outputId": "839a21fe-2337-4dcf-b9af-2916a8884b53"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We divide the downloaded dataset to three namely - training, test and validation sets\n",
        "X_train,X_val,y_train,y_val =train_test_split(X_train,y_train,test_size=.3)"
      ],
      "metadata": {
        "id": "lAPclImsVUrJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We dimension our dataset\n",
        "print((X_train.shape, y_train.shape))\n",
        "print((X_val.shape, y_val.shape))\n",
        "print((X_test.shape, y_test.shape))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-bXVFNiVYXe",
        "outputId": "4094292c-69cf-4c11-f4f6-8b1711c7625d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((35000, 32, 32, 3), (35000, 1))\n",
            "((15000, 32, 32, 3), (15000, 1))\n",
            "((10000, 32, 32, 3), (10000, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hot encoding - converting our target varaibles and getting the number of categories/classes\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "QY1DxSz2VcUA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_deep_model():\n",
        "    # We will now use the VGG19 as a deep convolutional neural network as a transfer learning model\n",
        "    num_classes = y_train.shape[1]\n",
        "\n",
        "    initial_model = VGG19(include_top=False,\n",
        "                          weights='imagenet',\n",
        "                          input_shape=(32, 32, 3),\n",
        "                          classes=num_classes)\n",
        "\n",
        "    # Define the Keras Sequential model with dense layers\n",
        "    model = Sequential()\n",
        "    model.add(initial_model)\n",
        "    model.add(Flatten())\n",
        "    #Add dense layers and RELU activation\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(128,activation='relu'))\n",
        "    #Adding dropouts neurons - regularization technique for neural network models\n",
        "    model.add(Dropout(.3))\n",
        "    model.add(Dense(num_classes,\n",
        "    activation='softmax'))\n",
        "    #Check model dimension\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "#We build and train our model\n",
        "model = convolutional_deep_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiO7bsIcVg-V",
        "outputId": "4e933dd2-adfa-42a7-8e79-a107a94fba45"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 1, 1, 512)         20024384  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20452554 (78.02 MB)\n",
            "Trainable params: 20452554 (78.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define the hyperparameters for our model\n",
        "batch_size = 100\n",
        "epochs = 50\n",
        "learn_rate = 0.01\n",
        "adam = Adam(learning_rate=learn_rate,beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\n",
        "#optimizer = Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "5eH2uBCqVn_g"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train, y_train,validation_data=(X_val, y_val),\n",
        "steps_per_epoch = X_train.shape[0]//batch_size,\n",
        "epochs=epochs, batch_size=batch_size,verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SshG78DwVwpC",
        "outputId": "c7be6e24-0004-42f9-efa9-aa254fc98bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "350/350 - 26s - loss: 2.2888 - accuracy: 0.1766 - val_loss: 1.8489 - val_accuracy: 0.2303 - 26s/epoch - 74ms/step\n",
            "Epoch 2/50\n",
            "350/350 - 21s - loss: 1.8750 - accuracy: 0.2283 - val_loss: 1.8079 - val_accuracy: 0.2585 - 21s/epoch - 60ms/step\n",
            "Epoch 3/50\n",
            "350/350 - 21s - loss: 1.7539 - accuracy: 0.2963 - val_loss: 1.5601 - val_accuracy: 0.3695 - 21s/epoch - 60ms/step\n",
            "Epoch 4/50\n",
            "350/350 - 21s - loss: 1.5482 - accuracy: 0.3803 - val_loss: 1.4158 - val_accuracy: 0.4479 - 21s/epoch - 61ms/step\n",
            "Epoch 5/50\n",
            "350/350 - 21s - loss: 1.3913 - accuracy: 0.4519 - val_loss: 1.2650 - val_accuracy: 0.4976 - 21s/epoch - 61ms/step\n",
            "Epoch 6/50\n",
            "350/350 - 21s - loss: 1.2498 - accuracy: 0.5204 - val_loss: 1.1552 - val_accuracy: 0.5643 - 21s/epoch - 61ms/step\n",
            "Epoch 7/50\n",
            "350/350 - 22s - loss: 1.2544 - accuracy: 0.5245 - val_loss: 1.1715 - val_accuracy: 0.5473 - 22s/epoch - 62ms/step\n",
            "Epoch 8/50\n",
            "350/350 - 22s - loss: 1.1174 - accuracy: 0.5903 - val_loss: 1.1899 - val_accuracy: 0.5641 - 22s/epoch - 62ms/step\n",
            "Epoch 9/50\n",
            "350/350 - 22s - loss: 1.1449 - accuracy: 0.6051 - val_loss: 1.0821 - val_accuracy: 0.6193 - 22s/epoch - 62ms/step\n",
            "Epoch 10/50\n",
            "350/350 - 22s - loss: 1.0243 - accuracy: 0.6445 - val_loss: 1.0771 - val_accuracy: 0.6174 - 22s/epoch - 62ms/step\n",
            "Epoch 11/50\n",
            "350/350 - 22s - loss: 0.9295 - accuracy: 0.6799 - val_loss: 1.0208 - val_accuracy: 0.6469 - 22s/epoch - 62ms/step\n",
            "Epoch 12/50\n",
            "350/350 - 22s - loss: 0.8572 - accuracy: 0.7051 - val_loss: 0.9584 - val_accuracy: 0.6671 - 22s/epoch - 63ms/step\n",
            "Epoch 13/50\n",
            "350/350 - 22s - loss: 0.7872 - accuracy: 0.7312 - val_loss: 0.9280 - val_accuracy: 0.6859 - 22s/epoch - 63ms/step\n",
            "Epoch 14/50\n",
            "350/350 - 22s - loss: 0.7218 - accuracy: 0.7553 - val_loss: 0.8872 - val_accuracy: 0.7108 - 22s/epoch - 63ms/step\n",
            "Epoch 15/50\n",
            "350/350 - 22s - loss: 0.6855 - accuracy: 0.7696 - val_loss: 0.9262 - val_accuracy: 0.7103 - 22s/epoch - 63ms/step\n",
            "Epoch 16/50\n",
            "350/350 - 22s - loss: 0.6217 - accuracy: 0.7907 - val_loss: 0.8273 - val_accuracy: 0.7245 - 22s/epoch - 63ms/step\n",
            "Epoch 17/50\n",
            "350/350 - 22s - loss: 0.5996 - accuracy: 0.8063 - val_loss: 0.8363 - val_accuracy: 0.7369 - 22s/epoch - 63ms/step\n",
            "Epoch 18/50\n",
            "350/350 - 22s - loss: 0.5584 - accuracy: 0.8185 - val_loss: 0.8849 - val_accuracy: 0.7177 - 22s/epoch - 62ms/step\n",
            "Epoch 19/50\n",
            "350/350 - 22s - loss: 0.5321 - accuracy: 0.8285 - val_loss: 0.9170 - val_accuracy: 0.7428 - 22s/epoch - 63ms/step\n",
            "Epoch 20/50\n",
            "350/350 - 22s - loss: 0.5095 - accuracy: 0.8401 - val_loss: 0.9092 - val_accuracy: 0.7451 - 22s/epoch - 62ms/step\n",
            "Epoch 21/50\n",
            "350/350 - 22s - loss: 0.4371 - accuracy: 0.8633 - val_loss: 0.8760 - val_accuracy: 0.7574 - 22s/epoch - 62ms/step\n",
            "Epoch 22/50\n",
            "350/350 - 22s - loss: 0.4154 - accuracy: 0.8690 - val_loss: 0.8156 - val_accuracy: 0.7586 - 22s/epoch - 62ms/step\n",
            "Epoch 23/50\n",
            "350/350 - 22s - loss: 0.3873 - accuracy: 0.8803 - val_loss: 0.9503 - val_accuracy: 0.7493 - 22s/epoch - 63ms/step\n",
            "Epoch 24/50\n",
            "350/350 - 22s - loss: 0.3737 - accuracy: 0.8866 - val_loss: 1.0607 - val_accuracy: 0.7406 - 22s/epoch - 62ms/step\n",
            "Epoch 25/50\n",
            "350/350 - 22s - loss: 0.3553 - accuracy: 0.8930 - val_loss: 0.8945 - val_accuracy: 0.7657 - 22s/epoch - 62ms/step\n",
            "Epoch 26/50\n",
            "350/350 - 22s - loss: 0.9567 - accuracy: 0.6697 - val_loss: 1.0172 - val_accuracy: 0.6772 - 22s/epoch - 62ms/step\n",
            "Epoch 27/50\n",
            "350/350 - 22s - loss: 0.6505 - accuracy: 0.7992 - val_loss: 0.9157 - val_accuracy: 0.7181 - 22s/epoch - 62ms/step\n",
            "Epoch 28/50\n",
            "350/350 - 22s - loss: 0.4335 - accuracy: 0.8648 - val_loss: 0.9111 - val_accuracy: 0.7683 - 22s/epoch - 62ms/step\n",
            "Epoch 29/50\n",
            "350/350 - 22s - loss: 0.3814 - accuracy: 0.8836 - val_loss: 0.8534 - val_accuracy: 0.7565 - 22s/epoch - 62ms/step\n",
            "Epoch 30/50\n",
            "350/350 - 22s - loss: 0.3081 - accuracy: 0.9077 - val_loss: 0.9615 - val_accuracy: 0.7753 - 22s/epoch - 62ms/step\n",
            "Epoch 31/50\n",
            "350/350 - 22s - loss: 0.2609 - accuracy: 0.9235 - val_loss: 0.8974 - val_accuracy: 0.7661 - 22s/epoch - 62ms/step\n",
            "Epoch 32/50\n",
            "350/350 - 22s - loss: 0.2405 - accuracy: 0.9299 - val_loss: 0.9100 - val_accuracy: 0.7699 - 22s/epoch - 63ms/step\n",
            "Epoch 33/50\n",
            "350/350 - 22s - loss: 0.2674 - accuracy: 0.9210 - val_loss: 1.0637 - val_accuracy: 0.7629 - 22s/epoch - 63ms/step\n",
            "Epoch 34/50\n",
            "350/350 - 22s - loss: 0.2382 - accuracy: 0.9296 - val_loss: 1.0128 - val_accuracy: 0.7573 - 22s/epoch - 63ms/step\n",
            "Epoch 35/50\n",
            "350/350 - 22s - loss: 0.2198 - accuracy: 0.9357 - val_loss: 1.0832 - val_accuracy: 0.7491 - 22s/epoch - 62ms/step\n",
            "Epoch 36/50\n",
            "350/350 - 22s - loss: 0.2519 - accuracy: 0.9263 - val_loss: 2.2583 - val_accuracy: 0.7665 - 22s/epoch - 63ms/step\n",
            "Epoch 37/50\n",
            "350/350 - 22s - loss: 0.2950 - accuracy: 0.9167 - val_loss: 1.0126 - val_accuracy: 0.7419 - 22s/epoch - 63ms/step\n",
            "Epoch 38/50\n",
            "350/350 - 22s - loss: 0.2285 - accuracy: 0.9378 - val_loss: 1.1721 - val_accuracy: 0.7725 - 22s/epoch - 63ms/step\n",
            "Epoch 39/50\n",
            "350/350 - 22s - loss: 0.1870 - accuracy: 0.9483 - val_loss: 1.0427 - val_accuracy: 0.7807 - 22s/epoch - 63ms/step\n",
            "Epoch 40/50\n",
            "350/350 - 22s - loss: 0.3834 - accuracy: 0.8892 - val_loss: 1.0813 - val_accuracy: 0.7550 - 22s/epoch - 63ms/step\n",
            "Epoch 41/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Traning accuracy pf 94.59% loss 0.1952\n",
        "#Plot the train and validation loss and accuracy\n",
        "f,ax = plt.subplots(2,1)\n",
        "#loss\n",
        "ax[0].plot(model.history.history['loss'],color='b', label='Training Loss')\n",
        "ax[0].plot(model.history.history['val_loss'],color='r', label='Validation Loss')"
      ],
      "metadata": {
        "id": "qDwDX8izV0E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy\n",
        "ax[1].plot(model.history.history['accuracy'],color='b',label='Training Accuracy')\n",
        "ax[1].plot(model.history.history['val_accuracy'],color='r',label='Validation Accuracy')"
      ],
      "metadata": {
        "id": "m9aAIBl2V4sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the training loas and accuracy\n",
        "plt.plot(np.arange(0, epochs),model.history.history[\"loss\"],\n",
        "label=\"train_loss\")\n",
        "plt.plot(np.arange(0, epochs),model.history.history[\"val_loss\"],\n",
        "label=\"val_loss\")\n",
        "plt.plot(np.arange(0, epochs),model.history.history[\"accuracy\"],\n",
        "label=\"train_acc\")\n",
        "plt.plot(np.arange(0, epochs),model.history.history[\"val_accuracy\"],\n",
        "label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on custom multi image classifier using using cifars10 data set\")\n",
        "plt.xlabel(\"Epoch number\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")"
      ],
      "metadata": {
        "id": "9Cahsr4uWKII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions with the model using the test data set\n",
        "y_pred =np.argmax(model.predict(X_test),axis=1)\n",
        "y_true = np.argmax(y_test,axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "id": "Z4xPh-AnWOes"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}